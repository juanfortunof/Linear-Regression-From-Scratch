 Linear Regression from Scratch

**[English]** A robust, custom implementation of Linear Regression in Python. Unlike standard libraries, this project builds the mathematical logic from the ground up using the **Normal Equation** and includes a comprehensive suite of automatic statistical diagnostics to validate regression assumptions.

## 游쥟릖 English Documentation

### Key Features
* **Pure Math Implementation:** Calculates weights ($w$) and bias ($b$) using the Normal Equation method $(\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{y}$ rather than "black box" solvers.
* **Automatic Data Validation:** The `Validator` class ensures input integrity, checking for missing values (NaNs), infinite values, data types, and dimensional consistency before training.
* **Statistical Assumption Checks:** The model automatically runs diagnostic tests after fitting to warn you of potential statistical violations:
    * **Linearity:** Ramsey RESET test.
    * **Normality of Residuals:** Jarque-Bera test.
    * **Homoscedasticity:** Breusch-Pagan test.
    * **Multicollinearity:** VIF and Correlation checks.
    * **Autocorrelation:** Durbin-Watson test (optional for Time Series).
* **Detailed Reporting:** Generates a full metrics report (MSE, RMSE, MAE, $R^2$) and visualization plots (Regression Line and Residuals).
* **Memory Safe:** Includes logic to downsample extremely large datasets for plotting and metrics to prevent RAM overflow.

### Requirements
Ensure you have the following libraries installed:

pip install numpy pandas matplotlib seaborn scipy
Usage ExampleThe API is designed to be intuitive, similar to Scikit-Learn.Pythonimport pandas as pd
from linear_regressor import LinearRegressor # Assuming your file is named linear_regressor.py

# 1. Load your data
df = pd.read_csv('your_data.csv')
X = df[['feature1', 'feature2']]
y = df['target']

# 2. Initialize the model
# Set TimeSeries=True if your data is time-dependent (enables Durbin-Watson test)
model = LinearRegressor(TimeSeries=False)

# 3. Train the model
# This will print warnings if statistical assumptions (like normality) are violated
model.fit(X, y)

# 4. Make predictions
predictions = model.predict(X)

# 5. Generate a performance report
# Calculates metrics and displays regression/residual plots
model.get_metrics_report(X, predictions, y.values, charts=True)
游쀯릖 Documentaci칩n en Espa침olCaracter칤sticas PrincipalesImplementaci칩n Matem치tica Pura: Calcula los pesos ($w$) y el sesgo ($b$) usando la Ecuaci칩n Normal $(\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{y}$ en lugar de solucionadores de caja negra.Validaci칩n Autom치tica de Datos: La clase Validator asegura la integridad de los datos, verificando valores faltantes (NaNs), infinitos, tipos de datos y consistencia dimensional antes del entrenamiento.Verificaci칩n de Supuestos Estad칤sticos: El modelo ejecuta pruebas de diagn칩stico autom치ticamente despu칠s del entrenamiento para advertir sobre posibles violaciones estad칤sticas:Linealidad: Test de Ramsey RESET.Normalidad de los Residuos: Test de Jarque-Bera.Homocedasticidad: Test de Breusch-Pagan.Multicolinealidad: Verificaciones de VIF y Correlaci칩n.Autocorrelaci칩n: Test de Durbin-Watson (opcional para Series Temporales).Reportes Detallados: Genera un reporte completo de m칠tricas (MSE, RMSE, MAE, $R^2$) y gr치ficos de visualizaci칩n (L칤nea de Regresi칩n y Residuos).Optimizaci칩n de Memoria: Incluye l칩gica para reducir la muestra (downsampling) en datasets extremadamente grandes para los gr치ficos y m칠tricas, evitando el desbordamiento de RAM.RequisitosAseg칰rate de tener instaladas las siguientes librer칤as:Bashpip install numpy pandas matplotlib seaborn scipy
Ejemplo de UsoLa API est치 dise침ada para ser intuitiva, similar a Scikit-Learn.Pythonimport pandas as pd
from linear_regressor import LinearRegressor # Asumiendo que tu archivo se llama linear_regressor.py

-------------

Regresi칩n Lineal desde Cero

**[Espa침ol]** Una implementaci칩n robusta y personalizada de Regresi칩n Lineal en Python. A diferencia de las librer칤as est치ndar, este proyecto construye la l칩gica matem치tica desde cero utilizando la **Ecuaci칩n Normal** e incluye un conjunto completo de diagn칩sticos estad칤sticos autom치ticos.

### Componentes Clave
* **Implementaci칩n Matem치tica Pura:** Calcula coeficientes ($w$) e intercepto ($b$) usando el m칠todo de la ecuaci칩n Normal $(\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{y}$ en vez de los "black box" solvers.
* **Validaci칩n de Datos Autom치tica:** La clase `Validator` se asegura de la integridad del input, chequea valores faltantes (NaNs), infinitos, tipos de datos, y consistencia dimensional antes de entrenar.
* **Chequeo de Tests Estad칤sticos:** El modelo corre test de diagnosticos automaticamente luego de entrenar para advertirte de posibles violaciones estad칤sticas:
    * **Linealidad:** Ramsey RESET test.
    * **Normalidad de Residuos:** Jarque-Bera test.
    * **Homocedasticidad:** Breusch-Pagan test.
    * **Multicolinealidad:** VIF y chequeos de correlaci칩n.
    * **Autocorrelaci칩n:** Test de Durbin-Watson (opcional para Seires de Tiempo).
* **Reportes detallados:** Genera un reporte con todas las m칠tricas (MSE, RMSE, MAE, $R^2$) y gr치ficos (L칤nea de Regressi칩n y Residuos).
* **Optimizado en Memoria:** Incluye l칩gica para disminuir el n칰mero de observaciones para gr치ficos y m칠tricas para prevenir desbordamiento en el RAM.

  ### Requerimentos
Asegurate de tener las siguientes librerias instaladas:

pip install numpy pandas matplotlib seaborn scipy

# 1. Cargar tus datos
df = pd.read_csv('tu_data.csv')
X = df[['feature1', 'feature2']]
y = df['target']

# 2. Inicializar el modelo
# Usa TimeSeries=True si tus datos dependen del tiempo (activa el test Durbin-Watson)
model = LinearRegressor(TimeSeries=False)

# 3. Entrenar el modelo
# Esto imprimir치 advertencias si se violan supuestos estad칤sticos (como la normalidad)
model.fit(X, y)

# 4. Hacer predicciones
predictions = model.predict(X)

# 5. Generar reporte de rendimiento
# Calcula m칠tricas y muestra gr치ficos de regresi칩n y residuos
model.get_metrics_report(X, predictions, y.values, charts=True)
