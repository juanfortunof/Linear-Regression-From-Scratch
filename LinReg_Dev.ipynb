{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e498bab4",
   "metadata": {},
   "source": [
    "Linear Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5bc37702",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from typing import Tuple\n",
    "import warnings\n",
    "# import statsmodels.api as sm\n",
    "# import statsmodels.stats.diagnostic as smd\n",
    "# from statsmodels.stats.stattools import durbin_watson, jarque_bera\n",
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "# from statsmodels.tools.tools import add_constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1af0fd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "data = datasets.fetch_california_housing()\n",
    "X = pd.DataFrame(data['data'], columns=data['feature_names'])\n",
    "y = pd.DataFrame(data['target'], columns=['Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "de645389",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_simple_train = X[['AveBedrms']].head(16000)\n",
    "X_simple_test = X[['AveBedrms']].tail(4640)\n",
    "\n",
    "X_mult = X.copy()\n",
    "X_mult_train = X_mult.head(16000)\n",
    "X_mult_test = X_mult.tail(4640)\n",
    "\n",
    "y_train = y.head(16000)\n",
    "y_test = y.tail(4640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ab49173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4dec16",
   "metadata": {},
   "source": [
    "Scikit Learn pred for Mult Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "26bd8f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 11)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pru_aux_R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "95b96672",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juans\\AppData\\Local\\Temp\\ipykernel_15756\\2405442057.py:24: UserWarning: Ramsey Test failed, your model has non-linear relations, try using polynomial or logarithmic convertions.\n",
      "  warnings.warn('Ramsey Test failed, your model has non-linear relations, try using polynomial or logarithmic convertions.')\n"
     ]
    }
   ],
   "source": [
    "def RamseyReset(X, y):\n",
    "\n",
    "    all_w = LinearRegressor._get_weights(X, y)\n",
    "    w1, b1 = all_w[0:-1], all_w[-1]\n",
    "    pred1 = X @ w1 + b1\n",
    "    pred1_sq = pred_pru ** 2\n",
    "    pred1_cu = pred_pru ** 3\n",
    "    ssrr = np.sum((pred1 - y)**2, axis=0)\n",
    "\n",
    "    X2 = np.hstack([X, pred1_sq, pred1_cu])\n",
    "    all_w_R = LinearRegressor._get_weights(X2, y)\n",
    "    w2, b2 = all_w_R[0:-1], all_w_R[-1]\n",
    "    pred2 = X2 @ w2 + b2\n",
    "    ssra = np.sum((pred2 - y)**2, axis=0)\n",
    "\n",
    "    q = 2\n",
    "    n = X.shape[0]\n",
    "    k = X.shape[1]\n",
    "\n",
    "    F = ((ssrr-ssra) / q) / (ssra / (n - k - q - 1)) \n",
    "    F = F[0]\n",
    "\n",
    "    if F > 3:\n",
    "        warnings.warn('Ramsey Test failed, your model has non-linear relations, try using polynomial or logarithmic convertions.')\n",
    "\n",
    "RamseyReset(X_mult_train.values, y_train.values)\n",
    "Fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301928ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8705042151218245\n"
     ]
    }
   ],
   "source": [
    "def check_DW(X, y):\n",
    "\n",
    "    all_w = LinearRegressor._get_weights(X, y)\n",
    "    w, b = all_w[:-1], all_w[-1]\n",
    "\n",
    "    pred = X @ w + b\n",
    "    res = y - pred\n",
    "    d = np.sum((res[:-1] - res[1:])**2) / np.sum(res **2)\n",
    "\n",
    "    \n",
    "\n",
    "check_DW(X_mult_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "08422114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9389904335366368"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.f.ppf(1-0.05, 8, 16000-8-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "40daca5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juans\\AppData\\Local\\Temp\\ipykernel_15756\\2207201497.py:24: UserWarning: The BP test shows that your model has heterocedaskicity problems, try transforming the dependent and independent variables.\n",
      "  warnings.warn('The BP test shows that your model has heterocedaskicity problems, try transforming the dependent and independent variables.')\n"
     ]
    }
   ],
   "source": [
    "def check_Heterocedaskicity(X, y):\n",
    "\n",
    "    all_w = LinearRegressor._get_weights(X, y)\n",
    "    w, b = all_w[:-1], all_w[-1]\n",
    "    pred = X @ w + b\n",
    "    res = y - pred\n",
    "    res_sq = res**2\n",
    "    n = X.shape[0]\n",
    "    k = X.shape[1]\n",
    "    ssr = np.sum(res_sq)\n",
    "\n",
    "    var_res = ssr / (n-k-1)\n",
    "    g =  res_sq / var_res\n",
    "\n",
    "    all_w2 = LinearRegressor._get_weights(X, g)\n",
    "    w2, b2 = all_w2[:-1], all_w2[-1]\n",
    "    pred2 = X @ w2 + b2\n",
    "\n",
    "    R2 = Metrics.get_R2(pred2, g)\n",
    "    LM = n * R2\n",
    "    chi_square_value = scipy.stats.chi2.ppf(1-0.05, k)\n",
    "\n",
    "    if LM > chi_square_value:\n",
    "        warnings.warn('The BP test shows that your model has heterocedaskicity problems, try transforming the dependent and independent variables.')\n",
    "        \n",
    "check_Heterocedaskicity(X_mult_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "152ac459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estadístico Jarque-Bera: 13584.7122\n",
      "13584.71215673286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juans\\AppData\\Local\\Temp\\ipykernel_15756\\4063093287.py:46: UserWarning: Jarque Bera test failed. The residuals are not normally distributed (JB > Chi^2_crit).\n",
      "  warnings.warn('Jarque Bera test failed. The residuals are not normally distributed (JB > Chi^2_crit).', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "from scipy.stats import chi2 # Necesaria para el valor crítico\n",
    "\n",
    "def test_JB_Corregido(X, y):\n",
    "\n",
    "    # 1. Regresión y Residuos\n",
    "    all_w = LinearRegressor._get_weights(X, y)\n",
    "    w, b = all_w[:-1], all_w[-1]\n",
    "    pred = X @ w + b\n",
    "    res = y - pred\n",
    "    n = X.shape[0]\n",
    "\n",
    "    # La media de residuos en MCO es ~0, pero se incluye por robustez\n",
    "    res_mean = np.mean(res) \n",
    "    \n",
    "    # --- 2. Momentos Centrales y Normalización ---\n",
    "    \n",
    "    # 2.1. Varianza (Momento central de orden 2)\n",
    "    M2 = np.sum((res - res_mean)**2) / n # Varianza muestral\n",
    "    \n",
    "    # Desviación estándar al cuadrado y al cubo para la normalización\n",
    "    std_dev = np.sqrt(M2)\n",
    "    \n",
    "    # 2.2. Asimetría (S)\n",
    "    M3 = np.sum((res - res_mean)**3) / n # Momento central de orden 3\n",
    "    S = M3 / (std_dev**3) # M3 normalizado por la desviación estándar al cubo\n",
    "    \n",
    "    # 2.3. Curtosis (K)\n",
    "    M4 = np.sum((res - res_mean)**4) / n # Momento central de orden 4\n",
    "    K = M4 / (std_dev**4) # M4 normalizado por la desviación estándar a la cuarta\n",
    "    \n",
    "    # --- 3. Estadístico JB ---\n",
    "    \n",
    "    # Fórmula correcta: utiliza la curtosis excesiva (K - 3)\n",
    "    JB = n / 6 * ((S**2) + ((K - 3)**2 / 4)) # <--- CORRECCIÓN CLAVE\n",
    "    \n",
    "    # --- 4. Evaluación ---\n",
    "    \n",
    "    # El valor crítico Chi-cuadrado para alpha=0.05 y GL=2 es ~5.991\n",
    "    JB_critic = chi2.ppf(1 - 0.05, 2)\n",
    "    \n",
    "    print(f\"Estadístico Jarque-Bera: {JB:.4f}\")\n",
    "    \n",
    "    if JB > JB_critic:\n",
    "        warnings.warn('Jarque Bera test failed. The residuals are not normally distributed (JB > Chi^2_crit).', UserWarning)\n",
    "    else:\n",
    "        print(\"Test de Jarque-Bera Aprobado. Los residuos son consistentes con una distribución normal.\")\n",
    "        \n",
    "    print(JB)\n",
    "\n",
    "test_JB_Corregido(X_mult_train.values, y_train.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56663fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13584.71215673286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juans\\AppData\\Local\\Temp\\ipykernel_15756\\419903723.py:24: UserWarning: Jarque Bera test failed. The residuals are not normally distributed.\n",
      "  warnings.warn('Jarque Bera test failed. The residuals are not normally distributed.')\n"
     ]
    }
   ],
   "source": [
    "def test_JB(X, y):\n",
    "\n",
    "    all_w = LinearRegressor._get_weights(X, y)\n",
    "    w, b = all_w[:-1], all_w[-1]\n",
    "\n",
    "    pred = X @ w + b\n",
    "    res = y - pred\n",
    "    n = X.shape[0]\n",
    "    res_mean = np.mean(res)\n",
    "\n",
    "    M2 = 1/n * np.sum((res-res_mean)**2)\n",
    "    M3 = 1/n * np.sum((res-res_mean)**3)\n",
    "    M4 = 1/n * np.sum((res-res_mean)**4)\n",
    "    std_dev = np.sqrt(M2)\n",
    "    \n",
    "    S = M3 / std_dev**3\n",
    "    K = M4 / std_dev**4\n",
    "\n",
    "    JB = n/6 * ((S**2) + ((K - 3)**2 / 4))\n",
    "\n",
    "    JB_critic = scipy.stats.chi2.ppf(1-0.05, 2)\n",
    "\n",
    "    if JB > JB_critic:\n",
    "        warnings.warn('Jarque Bera test failed. The residuals are not normally distributed.')\n",
    "\n",
    "\n",
    "test_JB(X_mult_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "3b2b5451",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juans\\AppData\\Local\\Temp\\ipykernel_15756\\1610847744.py:19: UserWarning: Multicolinearity test failed, This is a serious issue, check the correlation between your features, they should not be correlated.\n",
      "  warnings.warn('Multicolinearity test failed, This is a serious issue, check the correlation between your features, they should not be correlated.')\n"
     ]
    }
   ],
   "source": [
    "def check_multicolinearity(X):\n",
    "\n",
    "    VIFs = {col:0 for col in X.columns}\n",
    "\n",
    "    for col in X.columns:\n",
    "        X_aux = X.drop(col, axis=1)\n",
    "        y = X[col]\n",
    "\n",
    "        all_w = LinearRegressor._get_weights(X_aux, y)\n",
    "        w, b = all_w[:-1], all_w[-1]\n",
    "        pred = X_aux @ w + b\n",
    "        R2_aux = Metrics.get_R2(pred, y)\n",
    "\n",
    "        VIFs[col] = 1 / (1 - R2_aux)\n",
    "\n",
    "    for vif in VIFs.values():\n",
    "\n",
    "        if vif > 5:\n",
    "            warnings.warn('Multicolinearity test failed, This is a serious issue, check the correlation between your features, they should not be correlated.')\n",
    "            break\n",
    "\n",
    "check_multicolinearity(X_mult_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51f2f08",
   "metadata": {},
   "source": [
    "Now my implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a08ab2",
   "metadata": {},
   "source": [
    "Cosas a corregir del modelo.\n",
    "\n",
    "1. Divide y conquista: Tienes todo en una sola clase, eso lo hace dificil de mantener, trata de separar cada etapa.\n",
    "2. Trata de que todo este escrito con Numpy, en vez de recibir dataframes de pandas, trata de que solo se pueda recibir arrays de numpy y trabajar con ellos, o por lo menos separar o convertir al inicio y luego hacer todo el modelo con puro numpy.\n",
    "3. Separa las metricas y puedes crear una clase solo para ellas, de modo que sea mas legible y facil de mantener\n",
    "4. Que los tests del modelo sean netamente producto del modelo y no de otras librerias, sino pierde sentido porque no es \"desde cero\".\n",
    "5. Tu regresor tiene que ser a prueba de balas, preparalo para NaNs, tipos de datos coherentes, dimensiones de arrays correctas, variables categoricas.\n",
    "6. Usa Warnings en vez de prints, los print no sirven para produccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "1b14b64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Simple MAE: 0.982420666235715\n",
      "Ridge Simple MAE: 0.9828045748451621\n",
      "Lasso Simple MAE: 0.9845237667499999\n"
     ]
    }
   ],
   "source": [
    "LR = LinearRegression()\n",
    "RR = Ridge(alpha=1000)\n",
    "LassoR = Lasso(alpha=1000)\n",
    "\n",
    "LR.fit(X_simple_train, y_train)\n",
    "LR_pred = LR.predict(X_simple_test)\n",
    "\n",
    "RR.fit(X_simple_train, y_train)\n",
    "RR_pred = RR.predict(X_simple_test)\n",
    "\n",
    "LassoR.fit(X_simple_train, y_train)\n",
    "LassoR_pred = LassoR.predict(X_simple_test)\n",
    "\n",
    "print(f'Linear Simple MAE: {mean_absolute_error(y_test, LR_pred)}')\n",
    "print(f'Ridge Simple MAE: {mean_absolute_error(y_test, RR_pred)}')\n",
    "print(f'Lasso Simple MAE: {mean_absolute_error(y_test, LassoR_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "c984cfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "------------------METRICS REPORT-----------------\n",
      "\n",
      "MSE: 1.507\n",
      "RMSE: 1.228\n",
      "MAE: 0.982\n",
      "R2: 0.974\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juans\\AppData\\Local\\Temp\\ipykernel_15756\\4256537210.py:161: UserWarning: Ramsey Test failed, your model has non-linear relations, try using polynomial or logarithmic convertions.\n",
      "  warnings.warn('Ramsey Test failed, your model has non-linear relations, try using polynomial or logarithmic convertions.')\n",
      "C:\\Users\\juans\\AppData\\Local\\Temp\\ipykernel_15756\\4256537210.py:234: UserWarning: Jarque Bera test failed. The residuals are not normally distributed.\n",
      "  warnings.warn('Jarque Bera test failed. The residuals are not normally distributed.')\n",
      "C:\\Users\\juans\\AppData\\Local\\Temp\\ipykernel_15756\\4256537210.py:206: UserWarning: The BP test shows that your model has heterocedaskicity problems, try transforming the dependent and independent variables.\n",
      "  warnings.warn('The BP test shows that your model has heterocedaskicity problems, try transforming the dependent and independent variables.')\n"
     ]
    }
   ],
   "source": [
    "Juan_LR = LinearRegressor()\n",
    "Juan_LR.fit(X_simple_train, y_train)\n",
    "pred_Juan_simple = Juan_LR.predict(X_simple_test)\n",
    "Juan_LR.get_metrics_report(X_simple_test, pred_Juan_simple, y_test, charts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "2ecff524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Simple MAE: 0.5183922114609337\n",
      "Ridge Simple MAE: 0.52261892925488\n",
      "Lasso Simple MAE: 0.9845237667499999\n"
     ]
    }
   ],
   "source": [
    "LR.fit(X_mult_train, y_train)\n",
    "LR_pred_mult = LR.predict(X_mult_test)\n",
    "\n",
    "RR.fit(X_mult_train, y_train)\n",
    "RR_pred_mult = RR.predict(X_mult_test)\n",
    "\n",
    "LassoR.fit(X_mult_train, y_train)\n",
    "LassoR_pred_mult = LassoR.predict(X_mult_test)\n",
    "\n",
    "print(f'Linear Simple MAE: {mean_absolute_error(y_test, LR_pred_mult)}')\n",
    "print(f'Ridge Simple MAE: {mean_absolute_error(y_test, RR_pred_mult)}')\n",
    "print(f'Lasso Simple MAE: {mean_absolute_error(y_test, LassoR_pred_mult)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "13b70f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>5.8151</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.853448</td>\n",
       "      <td>1.017241</td>\n",
       "      <td>622.0</td>\n",
       "      <td>2.681034</td>\n",
       "      <td>37.75</td>\n",
       "      <td>-122.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>10.7569</td>\n",
       "      <td>52.0</td>\n",
       "      <td>7.450617</td>\n",
       "      <td>0.938272</td>\n",
       "      <td>465.0</td>\n",
       "      <td>2.870370</td>\n",
       "      <td>37.75</td>\n",
       "      <td>-122.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>9.3603</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6.765586</td>\n",
       "      <td>0.987531</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>2.718204</td>\n",
       "      <td>37.75</td>\n",
       "      <td>-122.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>6.1592</td>\n",
       "      <td>46.0</td>\n",
       "      <td>6.889362</td>\n",
       "      <td>1.157447</td>\n",
       "      <td>1293.0</td>\n",
       "      <td>2.751064</td>\n",
       "      <td>37.75</td>\n",
       "      <td>-122.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>4.6071</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.030189</td>\n",
       "      <td>1.075472</td>\n",
       "      <td>689.0</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>37.75</td>\n",
       "      <td>-122.47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0       8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1       8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2       7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3       5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4       3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "...        ...       ...       ...        ...         ...       ...       ...   \n",
       "15995   5.8151      52.0  6.853448   1.017241       622.0  2.681034     37.75   \n",
       "15996  10.7569      52.0  7.450617   0.938272       465.0  2.870370     37.75   \n",
       "15997   9.3603      51.0  6.765586   0.987531      1090.0  2.718204     37.75   \n",
       "15998   6.1592      46.0  6.889362   1.157447      1293.0  2.751064     37.75   \n",
       "15999   4.6071      52.0  6.030189   1.075472       689.0  2.600000     37.75   \n",
       "\n",
       "       Longitude  \n",
       "0        -122.23  \n",
       "1        -122.22  \n",
       "2        -122.24  \n",
       "3        -122.25  \n",
       "4        -122.25  \n",
       "...          ...  \n",
       "15995    -122.46  \n",
       "15996    -122.46  \n",
       "15997    -122.47  \n",
       "15998    -122.47  \n",
       "15999    -122.47  \n",
       "\n",
       "[16000 rows x 8 columns]"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mult_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "da5ecbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! HouseAge has a low correlation with the target variable. Corr: 0.11\n",
      "WARNING! AveRooms has a low correlation with the target variable. Corr: 0.14\n",
      "WARNING! AveBedrms has a low correlation with the target variable. Corr: -0.04\n",
      "WARNING! Population has a low correlation with the target variable. Corr: -0.03\n",
      "WARNING! AveOccup has a low correlation with the target variable. Corr: -0.05\n",
      "WARNING! Latitude has a low correlation with the target variable. Corr: -0.18\n",
      "WARNING! Longitude has a low correlation with the target variable. Corr: 0.02\n",
      "\n",
      "------------------METRICS REPORT-----------------\n",
      "\n",
      "MSE: 0.496\n",
      "RMSE: 0.704\n",
      "MAE: 0.52\n",
      "R2: 0.663\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juans\\AppData\\Local\\Temp\\ipykernel_15756\\272072085.py:248: UserWarning: Ramsey Test failed, your model has non-linear relations, try using polynomial or logarithmic convertions.\n",
      "  warnings.warn('Ramsey Test failed, your model has non-linear relations, try using polynomial or logarithmic convertions.')\n",
      "C:\\Users\\juans\\AppData\\Local\\Temp\\ipykernel_15756\\272072085.py:313: UserWarning: Jarque Bera test failed. The residuals are not normally distributed.\n",
      "  warnings.warn('Jarque Bera test failed. The residuals are not normally distributed.')\n",
      "C:\\Users\\juans\\AppData\\Local\\Temp\\ipykernel_15756\\272072085.py:288: UserWarning: The BP test shows that your model has heterocedaskicity problems, try transforming the dependent and independent variables.\n",
      "  warnings.warn('The BP test shows that your model has heterocedaskicity problems, try transforming the dependent and independent variables.')\n",
      "C:\\Users\\juans\\AppData\\Local\\Temp\\ipykernel_15756\\272072085.py:336: UserWarning: Multicolinearity test failed, This is a serious issue, check the correlation between your features, they should not be correlated.\n",
      "  warnings.warn('Multicolinearity test failed, This is a serious issue, check the correlation between your features, they should not be correlated.')\n"
     ]
    }
   ],
   "source": [
    "Juan_LR = LinearRegressor()\n",
    "Juan_LR.fit(X_mult_train, y_train)\n",
    "pred_Juan_mult = Juan_LR.predict(X_mult_test)\n",
    "Juan_LR.get_metrics_report(X_mult_test, pred_Juan_mult, y_test, charts=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "a36720f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "az = np.array([[0, 1, 2],\n",
    "               [0, 1, 2],\n",
    "               [0, 1, 2],\n",
    "               [0, 1, 2],\n",
    "               [0, 1, 2]])\n",
    "\n",
    "az2 = np.array([[0],\n",
    "                [0],\n",
    "                [0],\n",
    "                [0],\n",
    "                [0]])\n",
    "\n",
    "if az2 in az:\n",
    "    print('a')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
   "id": "e21969d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "a = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93d8a76e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.values.shape"
   ]
  },
  {
   "cell_type": "code",
=======
>>>>>>> 4c4821f0521bf293b609f328d1ddf0e9fbf48f74
   "execution_count": 329,
   "id": "c7ee3f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mult_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "06817283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "X_mult_train_scaled = ss.fit_transform(X_mult_train)\n",
    "X_mult_train_scaled.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "3423d945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MedInc\n",
      "HouseAge\n",
      "AveRooms\n",
      "AveBedrms\n",
      "Population\n",
      "AveOccup\n",
      "Latitude\n",
      "Longitude\n"
     ]
    }
   ],
   "source": [
    "for v in X_mult_train:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "20fe1ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in X_mult.T.duplicated():\n",
    "    if val:\n",
    "        print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "24e2d87c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MedInc           3.809342\n",
       "HouseAge        29.086875\n",
       "AveRooms         5.398881\n",
       "AveBedrms        1.103278\n",
       "Population    1447.327937\n",
       "AveOccup         3.008025\n",
       "Latitude        35.169198\n",
       "Longitude     -119.049152\n",
       "dtype: float64"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mult_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9127c2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "az3 = np.array([[1],\n",
    "                [2],\n",
    "                [np.NaN]])\n",
    "\n",
    "for val in az3:\n",
    "    if np.isnan(val):\n",
    "        print('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6706a88d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Matrix is singular. Your data has severe multicollinearity issues.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m     weights = (np.linalg.inv(input_b.T @ input_b) @ input_b.T) @ y\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m np.linalg.LinAlgError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mMatrix is singular. Your data has severe multicollinearity issues.\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Matrix is singular. Your data has severe multicollinearity issues."
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [2, 4, 6]})\n",
    "\n",
    "b = np.ones(shape=(X.shape[0], 1))\n",
    "input_b = np.hstack((X, b))\n",
    "\n",
    "try:\n",
    "    weights = (np.linalg.inv(input_b.T @ input_b) @ input_b.T) @ y\n",
    "except np.linalg.LinAlgError as e:\n",
    "    raise ValueError(\"Matrix is singular. Your data has severe multicollinearity issues.\") from None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdab7918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a\n",
       "0  1\n",
       "1  2\n",
       "2  3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X = pd.DataFrame({\"a\": [1, 2, 3], \"a\": [1, 2, 3]})\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5df564",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Validator:\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_type(X: pd.DataFrame | pd.Series, y: pd.DataFrame | pd.Series):\n",
    "\n",
    "        if not isinstance(y, pd.Series) and not isinstance(y, pd.DataFrame):\n",
    "            raise TypeError('The target feature should be a pandas Series or DataFrame.')\n",
    "        \n",
    "        if not isinstance(X, pd.Series) and not isinstance(X, pd.DataFrame):\n",
    "            raise TypeError('X should be a pandas Series or DataFrame.')\n",
    "\n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError('X and y should have the same amount of observations.')\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_values(X: pd.DataFrame | pd.Series, y: pd.DataFrame | pd.Series):\n",
    "\n",
    "        complete_df = pd.concat([X, y], axis=1)\n",
    "\n",
    "        for val in complete_df.values.flatten():\n",
    "            if val.isna() or np.isinf(val) or not val:\n",
    "                raise ValueError('Check the values of your data, there could be NaNs, inf or empty values.')\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_sizes(X: pd.DataFrame | pd.Series):\n",
    "\n",
    "        cols = X.shape[1]\n",
    "        rows = X.shape[0]\n",
    "\n",
    "        if cols > rows:\n",
    "            raise ValueError('Your dataset is too small, add more rows or more observations.')\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_features(X: pd.DataFrame | pd.Series, y: pd.DataFrame | pd.Series):\n",
    "\n",
    "        not_admited_types = ['object', 'datetime64', 'bool']\n",
    "        merged = pd.concat([X, y], axis=1)\n",
    "        dtypes = merged.dtypes\n",
    "\n",
    "        for data_type in dtypes:\n",
    "            if str(data_type) in not_admited_types:\n",
    "                raise TypeError('One of your features has a different type than numeric.')\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_duplicates(X: pd.DataFrame):\n",
    "\n",
    "        features = X.shape[1]\n",
    "        unique_features = set(features)\n",
    "\n",
    "        if len(unique_features) < len(features):\n",
    "            raise ValueError('It looks like there is one or more features duplicated on the dataset.')\n",
    "\n",
    "        is_duplicated = X.T.duplicated()\n",
    "\n",
    "        for val in is_duplicated:\n",
    "            if val:\n",
    "                raise ValueError('It looks like there is one or more features duplicated on the dataset.')\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_colinearity(X: pd.DataFrame):\n",
    "\n",
    "        corr = X.corr()\n",
    "\n",
    "        for val in corr.values.flatten():\n",
    "            if abs(val) > 0.8 and abs(val) < 1:\n",
    "                warnings.warn(\"There are clear signs of colinearity on your data, try using features that ain't correlated between them.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _validate(X: pd.DataFrame | pd.Series, y: pd.DataFrame | pd.Series):\n",
    "\n",
    "        Validator._check_type(X, y)\n",
    "        Validator._check_values(X, y)\n",
    "        Validator._check_sizes(X)\n",
    "        Validator._check_features(X, y)\n",
    "        Validator._check_scaled(X)\n",
    "\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            Validator._check_duplicates(X)\n",
    "            Validator._check_colinearity(X)\n",
    "\n",
    "class Preprocessor:\n",
    "\n",
    "    @staticmethod\n",
    "    def _convert_data(X: pd.DataFrame | pd.Series, y: pd.Series, train=True) -> Tuple[np.ndarray, np.ndarray]:\n",
    "\n",
    "        if isinstance(X, pd.Series):\n",
    "            X = X.values.reshape(-1, 1)\n",
    "        elif isinstance(X, pd.DataFrame):\n",
    "            X = X.values\n",
    "\n",
    "        if train:\n",
    "            if isinstance(y, pd.Series):\n",
    "                y = y.values.reshape(-1, 1)\n",
    "            elif isinstance(y, pd.DataFrame):\n",
    "                y = y.values\n",
    "\n",
    "            return X, y\n",
    "        \n",
    "        return X\n",
    "    \n",
    "\n",
    "class CorrChecker:\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_corr(X: pd.Series | pd.DataFrame, y: pd.Series) -> None:\n",
    "\n",
    "        df = pd.concat([X, y], axis=1)\n",
    "        corrs = df.corr().iloc[:, -1]\n",
    "\n",
    "        for col, corr in zip(corrs.index, corrs):\n",
    "            corr = np.round(corr, 2)\n",
    "            if abs(corr) < 0.3:\n",
    "                print(f'WARNING! {col} has a low correlation with the target variable. Corr: {corr}')\n",
    "\n",
    "\n",
    "class LinearRegressor:\n",
    "\n",
    "    def __init__(self, w=None, b=None, TimeSeries=False):\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        self.TimeSeries = TimeSeries\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_weights(X: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        b = np.ones(shape=(X.shape[0], 1))\n",
    "        input_b = np.hstack((X, b))\n",
    "\n",
    "        try:\n",
    "            weights = (np.linalg.inv(input_b.T @ input_b) @ input_b.T) @ y\n",
    "        except Exception as e:\n",
    "            raise ValueError(\"Matrix is singular. Your data still has multicollinearity issues.\")\n",
    "\n",
    "        return weights\n",
    "\n",
    "    def fit(self, X_train: pd.DataFrame | pd.Series, y_train: pd.Series) -> None:\n",
    "\n",
    "        '''\n",
    "            This method acts like training the model, it will also tell you if your\n",
    "            model has heterocedaskicity, autocorrelation, multicolinearity, is it\n",
    "            bad specified and if the data is normally distributed.\n",
    "        '''\n",
    "\n",
    "        Validator._validate(X_train, y_train)\n",
    "        CorrChecker._check_corr(X_train, y_train)\n",
    "        X_train_r, y_train_r = Preprocessor._convert_data(X_train, y_train)\n",
    "        w_b = self._get_weights(X_train_r, y_train_r)\n",
    "        self.w = w_b[:-1]\n",
    "        self.b = w_b[-1]\n",
    "        print()\n",
    "        \n",
    "        AssumpChecker._check_assumptions(X_train_r, y_train_r, self.w, self.b, self.TimeSeries)\n",
    "\n",
    "        if X_train.shape[1] > 1 and len(X_train.shape) > 1:\n",
    "            AssumpChecker._check_multicol(X_train)\n",
    "\n",
    "    def predict(self, X: pd.DataFrame | pd.Series) -> np.ndarray:\n",
    "\n",
    "        '''\n",
    "            This method predicts the test set using the weights and the Bias.\n",
    "        '''\n",
    "        X = Preprocessor._convert_data(X, np.array([1]), train=False)\n",
    "\n",
    "        pred = X @ self.w + self.b\n",
    "        return pred\n",
    "\n",
    "    def get_metrics_report(self,\n",
    "                           X: pd.DataFrame | pd.Series,\n",
    "                           pred: np.ndarray,\n",
    "                           y: np.ndarray,\n",
    "                           charts=True) -> None:\n",
    "\n",
    "        '''\n",
    "            This method will give you a quick report of you regression, showing you metrics\n",
    "            like RMSE, MSE, MAE, R2, a regression plot and a residual plot.\n",
    "        '''\n",
    "\n",
    "        X_res, y_res = Preprocessor._convert_data(X, y)\n",
    "\n",
    "        RMSE = Metrics.get_RMSE(pred, y_res)\n",
    "        MSE = Metrics.get_MSE(pred, y_res)\n",
    "        MAE = Metrics.get_MAE(pred, y_res)\n",
    "        R2 = Metrics.get_R2(pred, y_res)\n",
    "        residuals = y_res - pred\n",
    "\n",
    "        print('------------------METRICS REPORT-----------------\\n')\n",
    "        print(f'MSE: {np.round(MSE, 3)}\\nRMSE: {np.round(RMSE, 3)}\\nMAE: {np.round(MAE, 2)}\\nR2: {np.round(R2, 3)}\\n')\n",
    "\n",
    "        if charts:\n",
    "\n",
    "            if X_res.shape[1] == 1:\n",
    "                Report._get_regplot(X_res, pred, y_res)\n",
    "                print()\n",
    "\n",
    "            Report._get_residual_plot(pred, residuals)\n",
    "    \n",
    "    \n",
    "class AssumpChecker:\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_Ramsey(X: np.ndarray, y: np.ndarray, w: np.ndarray, b: np.ndarray) -> None:\n",
    "\n",
    "        ''' \n",
    "            This method does all the Ramsey process from start to finish, it\n",
    "            can be hard to understand, so I suggest supporting the explanations\n",
    "            with AI.\n",
    "        '''\n",
    "\n",
    "        w1, b1 = w, b\n",
    "        pred1 = X @ w1 + b1\n",
    "        pred1_sq = pred1 ** 2\n",
    "        pred1_cu = pred1 ** 3\n",
    "        ssrr = np.sum((y - pred1)**2, axis=0)\n",
    "\n",
    "        X2 = np.hstack([X, pred1_sq, pred1_cu])\n",
    "        all_w_R = LinearRegressor._get_weights(X2, y)\n",
    "        w2, b2 = all_w_R[0:-1], all_w_R[-1]\n",
    "        pred2 = X2 @ w2 + b2\n",
    "        ssra = np.sum((y - pred2)**2, axis=0)\n",
    "\n",
    "        q = 2\n",
    "        n = X.shape[0]\n",
    "        k = X.shape[1]\n",
    "\n",
    "        F = ((ssrr-ssra) / q) / (ssra / (n - k - q - 1)) \n",
    "        F = F[0]\n",
    "        F_critic = scipy.stats.f.ppf(1-0.05, k, n-k-q-1)\n",
    "\n",
    "        if F > F_critic:\n",
    "            warnings.warn('Ramsey Test failed, your model has non-linear relations, try using polynomial or logarithmic convertions.')\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_dw(X: np.ndarray, y: np.ndarray, w: np.ndarray, b: np.ndarray) -> None:\n",
    "\n",
    "        ''' This method just applies for Time Series data only, it does the Durbin Watson test. '''\n",
    "\n",
    "        pred = X @ w + b\n",
    "        res = y - pred\n",
    "        d = np.sum((res[:-1] - res[1:])**2) / np.sum(res **2)\n",
    "\n",
    "        if d < 1.8:\n",
    "            warnings.warn('Durbin Watson test shows that the model has positive correlation problems, try adding lags of one of the dependent variables as another dependent variable.')\n",
    "        elif d > 2.2:\n",
    "            warnings.warn('Durbin Watson test shows that the model has negative correlation problems, try adding lags of one of the dependent variables as another dependent variable.')\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_ht(X: np.ndarray, y: np.ndarray, w: np.ndarray, b: np.ndarray) -> None:\n",
    "\n",
    "        ''' This test checks for Heterocedaskicity on your model.'''\n",
    "\n",
    "        pred = X @ w + b\n",
    "        res = y - pred\n",
    "        res_sq = res**2\n",
    "        n = X.shape[0]\n",
    "        k = X.shape[1]\n",
    "        ssr = np.sum(res_sq)\n",
    "\n",
    "        var_res = ssr / (n-k-1)\n",
    "        g =  res_sq / var_res\n",
    "\n",
    "        all_w2 = LinearRegressor._get_weights(X, g)\n",
    "        w2, b2 = all_w2[:-1], all_w2[-1]\n",
    "        pred2 = X @ w2 + b2\n",
    "\n",
    "        R2 = Metrics.get_R2(pred2, g)\n",
    "        LM = n * R2\n",
    "        chi_square_value = scipy.stats.chi2.ppf(1-0.05, k)\n",
    "\n",
    "        if LM > chi_square_value:\n",
    "            warnings.warn('The BP test shows that your model has heterocedaskicity problems, try transforming the dependent and independent variables.')\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_jb(X: np.ndarray, y: np.ndarray, w: np.ndarray, b: np.ndarray) -> None:\n",
    "\n",
    "        ''' This is a private method '''\n",
    "\n",
    "        pred = X @ w + b\n",
    "        res = y - pred\n",
    "        n = X.shape[0]\n",
    "        res_mean = np.mean(res)\n",
    "\n",
    "        M2 = 1/n * np.sum((res-res_mean)**2)\n",
    "        M3 = 1/n * np.sum((res-res_mean)**3)\n",
    "        M4 = 1/n * np.sum((res-res_mean)**4)\n",
    "        std_dev = np.sqrt(M2)\n",
    "        \n",
    "        S = M3 / std_dev**3\n",
    "        K = M4 / std_dev**4\n",
    "\n",
    "        JB = n/6 * ((S**2) + ((K - 3)**2 / 4))\n",
    "\n",
    "        JB_critic = scipy.stats.chi2.ppf(1-0.05, 2)\n",
    "\n",
    "        if JB > JB_critic:\n",
    "            warnings.warn('Jarque Bera test failed. The residuals are not normally distributed.')\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_multicol(X: pd.DataFrame) -> None:\n",
    "\n",
    "        ''' This is a private method '''\n",
    "\n",
    "        VIFs = {col:0 for col in X.columns}\n",
    "\n",
    "        for col in X.columns:\n",
    "            X_aux = X.drop(col, axis=1)\n",
    "            y = X[col]\n",
    "\n",
    "            all_w = LinearRegressor._get_weights(X_aux.values, y.values)\n",
    "            w, b = all_w[:-1], all_w[-1]\n",
    "            pred = X_aux @ w + b\n",
    "            R2_aux = Metrics.get_R2(pred, y)\n",
    "\n",
    "            VIFs[col] = 1 / (1 - R2_aux)\n",
    "\n",
    "        for vif in VIFs.values():\n",
    "\n",
    "            if vif > 5:\n",
    "                warnings.warn('Multicolinearity test failed, This is a serious issue, check the correlation between your features, they should not be correlated.')\n",
    "                break\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_assumptions(X: np.ndarray, y: np.ndarray, w: np.ndarray, b: np.ndarray, TimeSeries = False) -> None:\n",
    "\n",
    "        ''' This is a private method '''\n",
    "\n",
    "        AssumpChecker._check_Ramsey(X, y, w, b)\n",
    "        AssumpChecker._check_jb(X, y, w, b)\n",
    "        AssumpChecker._check_ht(X, y, w, b)\n",
    "\n",
    "        if TimeSeries:\n",
    "            AssumpChecker._check_dw(X, y, w, b)\n",
    "\n",
    "\n",
    "class Metrics:\n",
    "\n",
    "    @staticmethod\n",
    "    def get_MSE(pred: np.ndarray, y: np.ndarray) -> float:\n",
    "\n",
    "        ''' This method calculates the MSE '''\n",
    "\n",
    "        m = pred.shape[0]\n",
    "\n",
    "        MSE = (1/m) * np.sum((y - pred) ** 2)\n",
    "        return MSE\n",
    "\n",
    "    @staticmethod\n",
    "    def get_RMSE(pred: np.ndarray, y: np.ndarray) -> float:\n",
    "\n",
    "        ''' This method calculates the RMSE '''\n",
    "\n",
    "        m = pred.shape[0]\n",
    "\n",
    "        RMSE = ((1/m) * np.sum((y - pred) ** 2)) ** 0.5\n",
    "        return RMSE\n",
    "\n",
    "    @staticmethod\n",
    "    def get_MAE(pred: np.ndarray, y: np.ndarray) -> float:\n",
    "\n",
    "        ''' This method calculates the MAE '''\n",
    "\n",
    "        m = pred.shape[0]\n",
    "\n",
    "        MAE = 1/m * (np.sum(abs(y - pred)))\n",
    "        return MAE\n",
    "\n",
    "    @staticmethod\n",
    "    def get_R2(pred: np.ndarray, y: np.ndarray) -> float:\n",
    "\n",
    "        ''' This method calculates the R2 '''\n",
    "\n",
    "        num = np.sum((y - pred) ** 2)\n",
    "        den = np.sum((y - y.mean()) ** 2)\n",
    "        R2 = 1 - (num / den)\n",
    "\n",
    "        return R2\n",
    "\n",
    "\n",
    "class Report:\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_regplot(X: np.ndarray, pred: np.ndarray, y: np.ndarray) -> None:\n",
    "\n",
    "        ''' This is a private method '''\n",
    "\n",
    "        plt.scatter(y, X, alpha=0.3)\n",
    "        plt.plot(pred, X, c='r')\n",
    "        plt.title('Regresion plot')\n",
    "        plt.xlabel('Input')\n",
    "        plt.ylabel('Actual Values')\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_residual_plot(pred: np.ndarray, residuals: np.ndarray) -> None:\n",
    "\n",
    "        ''' This is a private method '''\n",
    "\n",
    "        plt.scatter(pred, residuals)\n",
    "        plt.axhline(y=0, color='r', linestyle='--')\n",
    "        plt.xlabel('Predictions')\n",
    "        plt.ylabel('Residuals')\n",
    "        plt.title('Residuals Plot')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9677ad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeRegressor(LinearRegressor):\n",
    "\n",
    "    def __init__(self, alpha=1):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "\n",
    "    @classmethod\n",
    "    def _get_weights(self, input: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        b = np.ones(shape=(input.shape[0], 1))\n",
    "        input_b = np.hstack((input, b))\n",
    "\n",
    "        weights = (np.linalg.inv((input_b.T @ input_b) + self.alpha * np.eye(input_b.shape[1])) @ input_b.T) @ y\n",
    "\n",
    "        return weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
